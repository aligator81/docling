"""
Test script for Optimized Embedding Service

This script tests the optimized embedding service with all performance improvements:
- Batch processing (30 chunks per batch)
- Concurrent processing (8 concurrent batches) 
- Reduced rate limiting (0.5s instead of 3s)
- Database batch commits
"""

import asyncio
import time
import sys
import os

# Add the parent directory to the path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database import SessionLocal
from app.services.optimized_embedding_service import OptimizedEmbeddingService
from app.models import Document, DocumentChunk, Embedding

async def test_optimized_embedding_service():
    """Test the optimized embedding service"""
    print("ğŸ§ª Testing Optimized Embedding Service")
    print("=" * 50)
    
    db = SessionLocal()
    
    try:
        # Initialize the optimized service
        print("ğŸš€ Initializing OptimizedEmbeddingService...")
        service = OptimizedEmbeddingService(provider="openai")
        
        # Test configuration
        print(f"ğŸ“Š Service Configuration:")
        print(f"  â€¢ Batch size: {service.batch_size} chunks per batch")
        print(f"  â€¢ Concurrent batches: {service.max_concurrent_batches}")
        print(f"  â€¢ Rate limit delay: {service.rate_limit_delay}s (reduced from 3s)")
        print(f"  â€¢ Max retries: {service.max_retries}")
        
        # Get stats before processing
        print("\nğŸ“ˆ Pre-processing Statistics:")
        stats_before = service.get_embedding_stats(db)
        print(f"  â€¢ Total embeddings: {stats_before.get('total_embeddings', 0)}")
        
        # Find chunks that need embeddings
        chunks_needing_embeddings = db.query(DocumentChunk).join(
            Document, DocumentChunk.document_id == Document.id
        ).outerjoin(
            Embedding, DocumentChunk.id == Embedding.chunk_id
        ).filter(
            Embedding.id.is_(None)  # No embedding exists
        ).count()
        
        print(f"  â€¢ Chunks needing embeddings: {chunks_needing_embeddings}")
        
        if chunks_needing_embeddings == 0:
            print("âš ï¸ No chunks found that need embeddings. Creating test chunks...")
            # Create some test chunks if none exist
            test_doc = db.query(Document).first()
            if test_doc:
                test_chunks = [
                    DocumentChunk(
                        document_id=test_doc.id,
                        chunk_text=f"Test chunk {i} for optimized embedding service testing.",
                        chunk_index=i,
                        page_numbers=[1],
                        section_title=f"Test Section {i}",
                        chunk_type="paragraph",
                        token_count=10
                    ) for i in range(5)
                ]
                db.add_all(test_chunks)
                db.commit()
                print("âœ… Created 5 test chunks")
        
        # Test the optimized processing
        print("\nğŸ§ª Testing Optimized Processing...")
        start_time = time.time()
        
        result = await service.process_embeddings_from_db(db, resume=False)
        
        processing_time = time.time() - start_time
        
        print(f"\nğŸ“Š Test Results:")
        print(f"  â€¢ Success: {result.success}")
        print(f"  â€¢ Embeddings created: {result.embeddings_created}")
        print(f"  â€¢ Processing time: {processing_time:.2f} seconds")
        print(f"  â€¢ Rate: {result.embeddings_created/processing_time:.2f} chunks/second")
        
        if result.metadata:
            print(f"  â€¢ Failed embeddings: {result.metadata.get('failed_embeddings', 0)}")
            print(f"  â€¢ Final embedding count: {result.metadata.get('final_embedding_count', 0)}")
        
        # Get stats after processing
        print("\nğŸ“ˆ Post-processing Statistics:")
        stats_after = service.get_embedding_stats(db)
        print(f"  â€¢ Total embeddings: {stats_after.get('total_embeddings', 0)}")
        
        # Performance comparison
        if chunks_needing_embeddings > 0:
            original_estimated_time = chunks_needing_embeddings * 3  # 3s per chunk
            optimized_time = processing_time
            speedup = original_estimated_time / optimized_time if optimized_time > 0 else 0
            
            print(f"\nğŸš€ Performance Comparison:")
            print(f"  â€¢ Original estimated time: {original_estimated_time:.2f}s")
            print(f"  â€¢ Optimized actual time: {optimized_time:.2f}s")
            print(f"  â€¢ Speedup: {speedup:.1f}x faster")
        
        # Cleanup
        service.cleanup_checkpoint()
        print("\nâœ… Test completed successfully!")
        
    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        db.close()

async def test_batch_processing():
    """Test batch processing functionality specifically"""
    print("\nğŸ§ª Testing Batch Processing...")
    print("=" * 50)
    
    db = SessionLocal()
    
    try:
        service = OptimizedEmbeddingService(provider="openai")
        
        # Create test batch data
        test_texts = [
            f"Test text for batch processing {i}. This is a sample text for embedding generation."
            for i in range(10)
        ]
        
        print(f"ğŸ”„ Testing batch embedding generation for {len(test_texts)} texts...")
        start_time = time.time()
        
        embeddings = await service.get_batch_embeddings(test_texts)
        
        batch_time = time.time() - start_time
        
        print(f"âœ… Batch processing completed:")
        print(f"  â€¢ Texts processed: {len(test_texts)}")
        print(f"  â€¢ Embeddings generated: {len(embeddings)}")
        print(f"  â€¢ Batch processing time: {batch_time:.2f}s")
        print(f"  â€¢ Rate: {len(test_texts)/batch_time:.2f} texts/second")
        
        # Verify embeddings
        if embeddings:
            print(f"  â€¢ Embedding dimensions: {len(embeddings[0])}")
            print(f"  â€¢ All embeddings have same dimensions: {all(len(e) == len(embeddings[0]) for e in embeddings)}")
        
    except Exception as e:
        print(f"âŒ Batch processing test failed: {e}")
        
    finally:
        db.close()

if __name__ == "__main__":
    print("ğŸ§ª Optimized Embedding Service Test Suite")
    print("=" * 50)
    
    # Run tests
    asyncio.run(test_optimized_embedding_service())
    asyncio.run(test_batch_processing())
    
    print("\nğŸ‰ All tests completed!")